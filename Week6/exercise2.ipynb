{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "!unzip cats_and_dogs_filtered.zip"
      ],
      "metadata": {
        "id": "efPMDzukjceV"
      },
      "id": "efPMDzukjceV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "0fabbfcf-20b8-4f61-929a-23d6694d7a3a",
      "metadata": {
        "id": "0fabbfcf-20b8-4f61-929a-23d6694d7a3a"
      },
      "outputs": [],
      "source": [
        "import PIL.Image as Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "import glob\n",
        "from torchvision.models import AlexNet_Weights\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b0a8083d-0180-4887-a378-02cc6ad424c0",
      "metadata": {
        "id": "b0a8083d-0180-4887-a378-02cc6ad424c0"
      },
      "outputs": [],
      "source": [
        "def get_df(path, classes=['dogs', 'cats']):\n",
        "    paths = pd.DataFrame({'class': [], 'path': []})\n",
        "    for c in classes:\n",
        "        df = pd.DataFrame({\n",
        "            'class': c,\n",
        "            'path': glob.glob(path + c + '/*')\n",
        "        })\n",
        "\n",
        "        paths = pd.concat([paths, df])\n",
        "\n",
        "    paths.reset_index(inplace=False)\n",
        "\n",
        "    return paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c097bc47-4916-4710-9983-61017724c11b",
      "metadata": {
        "id": "c097bc47-4916-4710-9983-61017724c11b"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, classes, transform=None):\n",
        "        self.paths = df\n",
        "        self.classes = classes\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.paths.iloc[idx]\n",
        "        img = Image.open(row['path'])\n",
        "        if self.transform is not None:\n",
        "            return self.transform(img), self.classes[row['class']]\n",
        "        else:\n",
        "            return img, self.classes[row['class']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "771dab4d-1036-49da-98b8-abb94314c4ff",
      "metadata": {
        "id": "771dab4d-1036-49da-98b8-abb94314c4ff"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % LOG_INTERVAL == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "        train_losses.append(loss.item())\n",
        "        train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "c08ebc30-66e4-41ef-a990-259cbc84f1e5",
      "metadata": {
        "id": "c08ebc30-66e4-41ef-a990-259cbc84f1e5"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.data.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_losses.append(test_loss)\n",
        "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6ed33c0d-9c6c-4199-bdc0-535c1136a024",
      "metadata": {
        "id": "6ed33c0d-9c6c-4199-bdc0-535c1136a024",
        "outputId": "d2e4491f-bedb-4880-d0eb-b7e74f8379ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c332424d5f0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "BATCH_SIZE_TRAIN = 16\n",
        "BATCH_SIZE_TEST = 10\n",
        "LR = 0.0001\n",
        "LOG_INTERVAL = 10\n",
        "RANDOM_SEED = 1\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "TRANSFORM = T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Resize([224, 224]),\n",
        "    T.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "CLASSES = {'dogs': 0, 'cats': 1}\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f30bb1d7-0b28-4710-85dc-de7748493ec9",
      "metadata": {
        "id": "f30bb1d7-0b28-4710-85dc-de7748493ec9"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(get_df('cats_and_dogs_filtered/train/'), CLASSES, TRANSFORM)\n",
        "test_dataset = MyDataset(get_df('cats_and_dogs_filtered/validation/'), CLASSES, TRANSFORM)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE_TEST, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "62fc337d-9c18-49cd-b9b9-54669140fbf9",
      "metadata": {
        "id": "62fc337d-9c18-49cd-b9b9-54669140fbf9",
        "outputId": "d66d228a-fc35-4acb-9324-7a30a889bcb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/pytorch_vision_v0.10.0\n"
          ]
        }
      ],
      "source": [
        "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', weights=AlexNet_Weights.DEFAULT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5c39e807-5a20-4c08-bcb2-85cc24578c3d",
      "metadata": {
        "id": "5c39e807-5a20-4c08-bcb2-85cc24578c3d",
        "outputId": "260bce80-9af0-4e1b-d6f4-d8e0471b7d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f98b22f8-1fb2-4071-9d69-ed4e1c07f125",
      "metadata": {
        "id": "f98b22f8-1fb2-4071-9d69-ed4e1c07f125"
      },
      "outputs": [],
      "source": [
        "model.features.requires_grad = False\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    *model.classifier[:-1],\n",
        "    nn.Linear(4096, 2, bias=True)\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4f202446-c3ca-4277-a5a5-8130786f7f5c",
      "metadata": {
        "id": "4f202446-c3ca-4277-a5a5-8130786f7f5c",
        "outputId": "72d35679-6c9d-4f9e-c768-11127b6ecff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "aa0e5516-e124-43cd-a26e-2d0a55612848",
      "metadata": {
        "id": "aa0e5516-e124-43cd-a26e-2d0a55612848"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a82ae9b0-1a0a-43fe-b314-3e504816ad19",
      "metadata": {
        "id": "a82ae9b0-1a0a-43fe-b314-3e504816ad19"
      },
      "outputs": [],
      "source": [
        "train_losses = []\n",
        "train_counter = []\n",
        "test_losses = []\n",
        "test_counter = [i*len(train_loader.dataset) for i in range(EPOCHS + 1)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "8f8b0b23-19c2-4dd5-b053-565e9feb098b",
      "metadata": {
        "id": "8f8b0b23-19c2-4dd5-b053-565e9feb098b",
        "outputId": "366c19ef-9514-4ddd-8587-f54894466295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/2000 (0%)]\tLoss: 0.655984\n",
            "Train Epoch: 1 [160/2000 (8%)]\tLoss: 0.799318\n",
            "Train Epoch: 1 [320/2000 (16%)]\tLoss: 0.794429\n",
            "Train Epoch: 1 [480/2000 (24%)]\tLoss: 0.581421\n",
            "Train Epoch: 1 [640/2000 (32%)]\tLoss: 0.481661\n",
            "Train Epoch: 1 [800/2000 (40%)]\tLoss: 0.417426\n",
            "Train Epoch: 1 [960/2000 (48%)]\tLoss: 0.368466\n",
            "Train Epoch: 1 [1120/2000 (56%)]\tLoss: 0.462122\n",
            "Train Epoch: 1 [1280/2000 (64%)]\tLoss: 0.268285\n",
            "Train Epoch: 1 [1440/2000 (72%)]\tLoss: 0.319874\n",
            "Train Epoch: 1 [1600/2000 (80%)]\tLoss: 0.232401\n",
            "Train Epoch: 1 [1760/2000 (88%)]\tLoss: 0.250417\n",
            "Train Epoch: 1 [1920/2000 (96%)]\tLoss: 0.244852\n",
            "\n",
            "Test set: Avg. loss: 0.0277, Accuracy: 912/1000 (91%)\n",
            "\n",
            "Train Epoch: 2 [0/2000 (0%)]\tLoss: 0.362025\n",
            "Train Epoch: 2 [160/2000 (8%)]\tLoss: 0.351564\n",
            "Train Epoch: 2 [320/2000 (16%)]\tLoss: 0.163142\n",
            "Train Epoch: 2 [480/2000 (24%)]\tLoss: 0.321648\n",
            "Train Epoch: 2 [640/2000 (32%)]\tLoss: 0.233638\n",
            "Train Epoch: 2 [800/2000 (40%)]\tLoss: 0.360523\n",
            "Train Epoch: 2 [960/2000 (48%)]\tLoss: 0.222858\n",
            "Train Epoch: 2 [1120/2000 (56%)]\tLoss: 0.178902\n",
            "Train Epoch: 2 [1280/2000 (64%)]\tLoss: 0.149634\n",
            "Train Epoch: 2 [1440/2000 (72%)]\tLoss: 0.261308\n",
            "Train Epoch: 2 [1600/2000 (80%)]\tLoss: 0.217574\n",
            "Train Epoch: 2 [1760/2000 (88%)]\tLoss: 0.475066\n",
            "Train Epoch: 2 [1920/2000 (96%)]\tLoss: 0.270454\n",
            "\n",
            "Test set: Avg. loss: 0.0204, Accuracy: 936/1000 (94%)\n",
            "\n",
            "Train Epoch: 3 [0/2000 (0%)]\tLoss: 0.251329\n",
            "Train Epoch: 3 [160/2000 (8%)]\tLoss: 0.122460\n",
            "Train Epoch: 3 [320/2000 (16%)]\tLoss: 0.253299\n",
            "Train Epoch: 3 [480/2000 (24%)]\tLoss: 0.134579\n",
            "Train Epoch: 3 [640/2000 (32%)]\tLoss: 0.151983\n",
            "Train Epoch: 3 [800/2000 (40%)]\tLoss: 0.212894\n",
            "Train Epoch: 3 [960/2000 (48%)]\tLoss: 0.143018\n",
            "Train Epoch: 3 [1120/2000 (56%)]\tLoss: 0.089267\n",
            "Train Epoch: 3 [1280/2000 (64%)]\tLoss: 0.286806\n",
            "Train Epoch: 3 [1440/2000 (72%)]\tLoss: 0.238343\n",
            "Train Epoch: 3 [1600/2000 (80%)]\tLoss: 0.107468\n",
            "Train Epoch: 3 [1760/2000 (88%)]\tLoss: 0.119857\n",
            "Train Epoch: 3 [1920/2000 (96%)]\tLoss: 0.243947\n",
            "\n",
            "Test set: Avg. loss: 0.0170, Accuracy: 947/1000 (95%)\n",
            "\n",
            "Train Epoch: 4 [0/2000 (0%)]\tLoss: 0.084472\n",
            "Train Epoch: 4 [160/2000 (8%)]\tLoss: 0.219276\n",
            "Train Epoch: 4 [320/2000 (16%)]\tLoss: 0.091628\n",
            "Train Epoch: 4 [480/2000 (24%)]\tLoss: 0.448252\n",
            "Train Epoch: 4 [640/2000 (32%)]\tLoss: 0.313148\n",
            "Train Epoch: 4 [800/2000 (40%)]\tLoss: 0.278203\n",
            "Train Epoch: 4 [960/2000 (48%)]\tLoss: 0.173574\n",
            "Train Epoch: 4 [1120/2000 (56%)]\tLoss: 0.206129\n",
            "Train Epoch: 4 [1280/2000 (64%)]\tLoss: 0.083258\n",
            "Train Epoch: 4 [1440/2000 (72%)]\tLoss: 0.138627\n",
            "Train Epoch: 4 [1600/2000 (80%)]\tLoss: 0.082557\n",
            "Train Epoch: 4 [1760/2000 (88%)]\tLoss: 0.100802\n",
            "Train Epoch: 4 [1920/2000 (96%)]\tLoss: 0.170342\n",
            "\n",
            "Test set: Avg. loss: 0.0150, Accuracy: 951/1000 (95%)\n",
            "\n",
            "Train Epoch: 5 [0/2000 (0%)]\tLoss: 0.084157\n",
            "Train Epoch: 5 [160/2000 (8%)]\tLoss: 0.157885\n",
            "Train Epoch: 5 [320/2000 (16%)]\tLoss: 0.091337\n",
            "Train Epoch: 5 [480/2000 (24%)]\tLoss: 0.214095\n",
            "Train Epoch: 5 [640/2000 (32%)]\tLoss: 0.196220\n",
            "Train Epoch: 5 [800/2000 (40%)]\tLoss: 0.096491\n",
            "Train Epoch: 5 [960/2000 (48%)]\tLoss: 0.324143\n",
            "Train Epoch: 5 [1120/2000 (56%)]\tLoss: 0.244054\n",
            "Train Epoch: 5 [1280/2000 (64%)]\tLoss: 0.332410\n",
            "Train Epoch: 5 [1440/2000 (72%)]\tLoss: 0.096104\n",
            "Train Epoch: 5 [1600/2000 (80%)]\tLoss: 0.105946\n",
            "Train Epoch: 5 [1760/2000 (88%)]\tLoss: 0.081128\n",
            "Train Epoch: 5 [1920/2000 (96%)]\tLoss: 0.168102\n",
            "\n",
            "Test set: Avg. loss: 0.0137, Accuracy: 956/1000 (96%)\n",
            "\n",
            "Train Epoch: 6 [0/2000 (0%)]\tLoss: 0.085796\n",
            "Train Epoch: 6 [160/2000 (8%)]\tLoss: 0.065569\n",
            "Train Epoch: 6 [320/2000 (16%)]\tLoss: 0.056400\n",
            "Train Epoch: 6 [480/2000 (24%)]\tLoss: 0.060540\n",
            "Train Epoch: 6 [640/2000 (32%)]\tLoss: 0.035459\n",
            "Train Epoch: 6 [800/2000 (40%)]\tLoss: 0.022501\n",
            "Train Epoch: 6 [960/2000 (48%)]\tLoss: 0.140267\n",
            "Train Epoch: 6 [1120/2000 (56%)]\tLoss: 0.170510\n",
            "Train Epoch: 6 [1280/2000 (64%)]\tLoss: 0.225736\n",
            "Train Epoch: 6 [1440/2000 (72%)]\tLoss: 0.040336\n",
            "Train Epoch: 6 [1600/2000 (80%)]\tLoss: 0.087689\n",
            "Train Epoch: 6 [1760/2000 (88%)]\tLoss: 0.047006\n",
            "Train Epoch: 6 [1920/2000 (96%)]\tLoss: 0.063196\n",
            "\n",
            "Test set: Avg. loss: 0.0125, Accuracy: 961/1000 (96%)\n",
            "\n",
            "Train Epoch: 7 [0/2000 (0%)]\tLoss: 0.087915\n",
            "Train Epoch: 7 [160/2000 (8%)]\tLoss: 0.033107\n",
            "Train Epoch: 7 [320/2000 (16%)]\tLoss: 0.064966\n",
            "Train Epoch: 7 [480/2000 (24%)]\tLoss: 0.169487\n",
            "Train Epoch: 7 [640/2000 (32%)]\tLoss: 0.155631\n",
            "Train Epoch: 7 [800/2000 (40%)]\tLoss: 0.255177\n",
            "Train Epoch: 7 [960/2000 (48%)]\tLoss: 0.459203\n",
            "Train Epoch: 7 [1120/2000 (56%)]\tLoss: 0.332505\n",
            "Train Epoch: 7 [1280/2000 (64%)]\tLoss: 0.104649\n",
            "Train Epoch: 7 [1440/2000 (72%)]\tLoss: 0.078803\n",
            "Train Epoch: 7 [1600/2000 (80%)]\tLoss: 0.056188\n",
            "Train Epoch: 7 [1760/2000 (88%)]\tLoss: 0.226457\n",
            "Train Epoch: 7 [1920/2000 (96%)]\tLoss: 0.163742\n",
            "\n",
            "Test set: Avg. loss: 0.0118, Accuracy: 962/1000 (96%)\n",
            "\n",
            "Train Epoch: 8 [0/2000 (0%)]\tLoss: 0.159301\n",
            "Train Epoch: 8 [160/2000 (8%)]\tLoss: 0.057395\n",
            "Train Epoch: 8 [320/2000 (16%)]\tLoss: 0.345872\n",
            "Train Epoch: 8 [480/2000 (24%)]\tLoss: 0.081366\n",
            "Train Epoch: 8 [640/2000 (32%)]\tLoss: 0.105541\n",
            "Train Epoch: 8 [800/2000 (40%)]\tLoss: 0.120371\n",
            "Train Epoch: 8 [960/2000 (48%)]\tLoss: 0.268553\n",
            "Train Epoch: 8 [1120/2000 (56%)]\tLoss: 0.120376\n",
            "Train Epoch: 8 [1280/2000 (64%)]\tLoss: 0.131133\n",
            "Train Epoch: 8 [1440/2000 (72%)]\tLoss: 0.094777\n",
            "Train Epoch: 8 [1600/2000 (80%)]\tLoss: 0.103493\n",
            "Train Epoch: 8 [1760/2000 (88%)]\tLoss: 0.034035\n",
            "Train Epoch: 8 [1920/2000 (96%)]\tLoss: 0.091324\n",
            "\n",
            "Test set: Avg. loss: 0.0112, Accuracy: 965/1000 (97%)\n",
            "\n",
            "Train Epoch: 9 [0/2000 (0%)]\tLoss: 0.116352\n",
            "Train Epoch: 9 [160/2000 (8%)]\tLoss: 0.025237\n",
            "Train Epoch: 9 [320/2000 (16%)]\tLoss: 0.178482\n",
            "Train Epoch: 9 [480/2000 (24%)]\tLoss: 0.079516\n",
            "Train Epoch: 9 [640/2000 (32%)]\tLoss: 0.226465\n",
            "Train Epoch: 9 [800/2000 (40%)]\tLoss: 0.189072\n",
            "Train Epoch: 9 [960/2000 (48%)]\tLoss: 0.057324\n",
            "Train Epoch: 9 [1120/2000 (56%)]\tLoss: 0.221105\n",
            "Train Epoch: 9 [1280/2000 (64%)]\tLoss: 0.096818\n",
            "Train Epoch: 9 [1440/2000 (72%)]\tLoss: 0.144953\n",
            "Train Epoch: 9 [1600/2000 (80%)]\tLoss: 0.076131\n",
            "Train Epoch: 9 [1760/2000 (88%)]\tLoss: 0.040683\n",
            "Train Epoch: 9 [1920/2000 (96%)]\tLoss: 0.133977\n",
            "\n",
            "Test set: Avg. loss: 0.0108, Accuracy: 965/1000 (97%)\n",
            "\n",
            "Train Epoch: 10 [0/2000 (0%)]\tLoss: 0.054182\n",
            "Train Epoch: 10 [160/2000 (8%)]\tLoss: 0.033716\n",
            "Train Epoch: 10 [320/2000 (16%)]\tLoss: 0.093952\n",
            "Train Epoch: 10 [480/2000 (24%)]\tLoss: 0.199538\n",
            "Train Epoch: 10 [640/2000 (32%)]\tLoss: 0.026121\n",
            "Train Epoch: 10 [800/2000 (40%)]\tLoss: 0.176502\n",
            "Train Epoch: 10 [960/2000 (48%)]\tLoss: 0.064091\n",
            "Train Epoch: 10 [1120/2000 (56%)]\tLoss: 0.047163\n",
            "Train Epoch: 10 [1280/2000 (64%)]\tLoss: 0.255995\n",
            "Train Epoch: 10 [1440/2000 (72%)]\tLoss: 0.771043\n",
            "Train Epoch: 10 [1600/2000 (80%)]\tLoss: 0.136002\n",
            "Train Epoch: 10 [1760/2000 (88%)]\tLoss: 0.097626\n",
            "Train Epoch: 10 [1920/2000 (96%)]\tLoss: 0.037626\n",
            "\n",
            "Test set: Avg. loss: 0.0104, Accuracy: 963/1000 (96%)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(epoch)\n",
        "    test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af4fe1de-206a-4124-9cee-2dfb112d8bbb",
      "metadata": {
        "id": "af4fe1de-206a-4124-9cee-2dfb112d8bbb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}